{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e816908-ff5e-46ba-a1ee-ece6b4f936bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GWAS summary data decompressed successfully.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Rule: Ensure the correct path for the input and output files.\n",
    "with gzip.open('CAD_META.gz', 'rb') as f_in:\n",
    "    with open('CAD_META.txt', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(\"GWAS summary data decompressed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f703fe47-d5b5-42fc-b839-54b268bed307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8c825a-cf7d-47b0-b403-f0359a1cf344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         MarkerName Allele1 Allele2   Freq1  FreqSE  MinFreq  MaxFreq  Effect  \\\n",
      "0  10:100000625_A_G       a       g  0.5604  0.0081   0.5499   0.5667  0.0264   \n",
      "1  10:100000645_A_C       a       c  0.8060  0.0089   0.7996   0.8184 -0.0119   \n",
      "2  10:100001867_C_T       t       c  0.0129  0.0007   0.0114   0.0132  0.0296   \n",
      "3  10:100003242_G_T       t       g  0.8800  0.0034   0.8756   0.8827  0.0107   \n",
      "4  10:100003304_A_G       a       g  0.9636  0.0037   0.9615   0.9701  0.0066   \n",
      "5  10:100003785_C_T       t       c  0.6432  0.0006   0.6425   0.6437 -0.0203   \n",
      "6  10:100004360_A_G       a       g  0.1939  0.0090   0.1814   0.2004  0.0120   \n",
      "7  10:100004441_C_G       c       g  0.6328  0.0029   0.6290   0.6350 -0.0196   \n",
      "8  10:100004799_A_C       a       c  0.9863  0.0014   0.9857   0.9891 -0.0185   \n",
      "9  10:100004906_A_C       a       c  0.4395  0.0081   0.4332   0.4500 -0.0265   \n",
      "\n",
      "   StdErr   P-value Direction  HetISq  HetChiSq  HetDf  HetPVal        oldID  \\\n",
      "0  0.0056  0.000003        ++    13.0     1.150      1   0.2835    rs7899632   \n",
      "1  0.0071  0.094480        --     0.0     0.578      1   0.4469   rs61875309   \n",
      "2  0.0293  0.312600        -+     0.0     0.485      1   0.4861  rs150203744   \n",
      "3  0.0086  0.213600        ++     0.0     0.002      1   0.9642   rs12258651   \n",
      "4  0.0158  0.678700        -+    53.3     2.142      1   0.1433   rs72828461   \n",
      "5  0.0058  0.000499        --     0.0     0.174      1   0.6768    rs1359508   \n",
      "6  0.0071  0.092200        ++     0.0     0.608      1   0.4355    rs1048754   \n",
      "7  0.0058  0.000733        --     0.0     0.117      1   0.7318    rs1048757   \n",
      "8  0.0267  0.487300        --    30.6     1.441      1   0.2299   rs77264786   \n",
      "9  0.0056  0.000002        --    16.5     1.198      1   0.2737    rs3750595   \n",
      "\n",
      "   CHR         BP  \n",
      "0   10  100000625  \n",
      "1   10  100000645  \n",
      "2   10  100001867  \n",
      "3   10  100003242  \n",
      "4   10  100003304  \n",
      "5   10  100003785  \n",
      "6   10  100004360  \n",
      "7   10  100004441  \n",
      "8   10  100004799  \n",
      "9   10  100004906  \n",
      "Index(['MarkerName', 'Allele1', 'Allele2', 'Freq1', 'FreqSE', 'MinFreq',\n",
      "       'MaxFreq', 'Effect', 'StdErr', 'P-value', 'Direction', 'HetISq',\n",
      "       'HetChiSq', 'HetDf', 'HetPVal', 'oldID', 'CHR', 'BP'],\n",
      "      dtype='object')\n",
      "(7947837, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7947837 entries, 0 to 7947836\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   MarkerName  object \n",
      " 1   Allele1     object \n",
      " 2   Allele2     object \n",
      " 3   Freq1       float64\n",
      " 4   FreqSE      float64\n",
      " 5   MinFreq     float64\n",
      " 6   MaxFreq     float64\n",
      " 7   Effect      float64\n",
      " 8   StdErr      float64\n",
      " 9   P-value     float64\n",
      " 10  Direction   object \n",
      " 11  HetISq      float64\n",
      " 12  HetChiSq    float64\n",
      " 13  HetDf       int64  \n",
      " 14  HetPVal     float64\n",
      " 15  oldID       object \n",
      " 16  CHR         int64  \n",
      " 17  BP          int64  \n",
      "dtypes: float64(10), int64(3), object(5)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "Data cleaned and significant SNPs extracted.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file path for decompressed file\n",
    "Genetic_Data_Summary = \"C:/Users/emman/Downloads/PM2.5_Pollution_Data-Public/Scripts/Genetic_Data/New_Genetic_Data/CAD_META.txt\"  # Replace with your actual path\n",
    "\n",
    "# Try reading the file in chunks if it's too large\n",
    "chunk_size = 10000  # Number of rows per chunk\n",
    "chunks = pd.read_csv(Genetic_Data_Summary, delimiter='\\t', chunksize=chunk_size, engine='python')  # Removed low_memory\n",
    "\n",
    "# Concatenate chunks into a single DataFrame\n",
    "genetic_df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# Display first 10 rows to verify loading\n",
    "print(genetic_df.head(10))\n",
    "\n",
    "# Display columns to understand dataset structure\n",
    "print(genetic_df.columns)\n",
    "print(genetic_df.shape)\n",
    "\n",
    "# Get basic info on data types and non-null counts\n",
    "print(genetic_df.info())\n",
    "\n",
    "# Rule: Clean the data by removing rows with missing critical data and filter significant variants.\n",
    "# Use 'MarkerName' and 'P-value' instead of 'SNP' and 'P'\n",
    "genetic_df_cleaned = genetic_df.dropna(subset=['MarkerName', 'Effect', 'P-value'])  # Remove missing critical data\n",
    "significant_genetic_df = genetic_df_cleaned[genetic_df_cleaned['P-value'] < 5e-8]  # Filter by p-value threshold\n",
    "\n",
    "# Save cleaned data for future use\n",
    "significant_genetic_df.to_csv('significant_genetic_data.csv', index=False)\n",
    "print(\"Data cleaned and significant SNPs extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2073e1e-df40-41eb-a3ef-4ca46481df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel file downloaded!\n",
      "Found 91 GBR samples.\n",
      "['HG00096', 'HG00097', 'HG00099', 'HG00100', 'HG00101', 'HG00102', 'HG00103', 'HG00105', 'HG00106', 'HG00107']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Step 1: Download the panel file (if you haven't downloaded manually)\n",
    "url = 'https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel'\n",
    "panel_file = 'integrated_call_samples_v3.20130502.ALL.panel'\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(panel_file, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"Panel file downloaded!\")\n",
    "\n",
    "# Step 2: Read panel file and extract GBR sample IDs\n",
    "panel_df = pd.read_csv(panel_file, sep='\\t')\n",
    "gbr_samples = panel_df[panel_df['pop'] == 'GBR']\n",
    "gbr_sample_ids = gbr_samples['sample'].tolist()\n",
    "\n",
    "# Save GBR sample IDs to a file\n",
    "with open('GBR_sample_ids.txt', 'w') as f:\n",
    "    for sample_id in gbr_sample_ids:\n",
    "        f.write(sample_id + '\\n')\n",
    "\n",
    "print(f\"Found {len(gbr_sample_ids)} GBR samples.\")\n",
    "print(gbr_sample_ids[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac0d05c0-caed-422a-899b-33758ffc771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample  pop super_pop  gender  Unnamed: 4  Unnamed: 5\n",
      "0  HG00096  GBR       EUR    male         NaN         NaN\n",
      "1  HG00097  GBR       EUR  female         NaN         NaN\n",
      "2  HG00099  GBR       EUR  female         NaN         NaN\n",
      "3  HG00100  GBR       EUR  female         NaN         NaN\n",
      "4  HG00101  GBR       EUR    male         NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load sample metadata (population info, sample IDs)\n",
    "samples = pd.read_csv('integrated_call_samples_v3.20130502.ALL.panel', sep='\\t')\n",
    "print(samples.head())\n",
    "\n",
    "# Columns usually: sample, population, super_population, gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28690cb9-53b4-489b-8ad2-cc39195918c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea13ab-3dfa-4a64-bd5f-cfe62eeba94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32ef0f-d7a9-4d38-8108-ff1faeb705f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel              # From scikit-allel: for VCF parsing and genotype analysis\n",
    "import os                 # For file path and existence checks\n",
    "\n",
    "# File paths\n",
    "vcf_path = r\"ALL.chr1.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes (1).vcf.gz\"\n",
    "samples_path = \"integrated_call_samples_v3.20130502.ALL.panel\"\n",
    "output_file = \"allele_freq_chr1.csv.gz\"  # Output will be compressed CSV\n",
    "\n",
    "print(\"VCF file exists:\", os.path.exists(vcf_path))#Check VCF File Exists\n",
    "\n",
    "# Load samples info and filter EUR samples\n",
    "samples_df = pd.read_csv(samples_path, sep=\"\\t\")## Load sample panel\n",
    "eur_samples = samples_df[samples_df['super_pop'] == 'EUR']['sample'].tolist()#Loads metadata and filters for European ancestry samples\n",
    "\n",
    "# Prepare chunk parameters\n",
    "chunk_size = 50_000 #Number of variants per chunk\n",
    "chrom = '1' #Target chromosome\n",
    "\n",
    "# Read all positions for chromosome 1 to identify variant locations.\n",
    "vcf_all_pos = allel.read_vcf(vcf_path, fields=['variants/CHROM', 'variants/POS'])\n",
    "positions = vcf_all_pos['variants/POS']\n",
    "chroms = vcf_all_pos['variants/CHROM']\n",
    "\n",
    "# Filter chromosome 1 positions and Create a mask for chromosome 1 and filters positions accordingly.\n",
    "chr1_mask = chroms == chrom\n",
    "chr1_positions = positions[chr1_mask]\n",
    "\n",
    "# Remove old output file if exists\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Iterate and write chunks directly to CSV\n",
    "start_idx = 0#Initializes loop variables\n",
    "first_chunk = True\n",
    "total_variants_chr1 = len(chr1_positions)#calculates total number of variants.\n",
    "\n",
    "# Batch size for writing to disk to reduce I/O frequency\n",
    "batch_size = 10  # Number of chunks to process before saving\n",
    "\n",
    "while start_idx < total_variants_chr1:#Loops through all variants in chunks.\n",
    "    end_idx = min(start_idx + chunk_size, total_variants_chr1)\n",
    "    start_pos = chr1_positions[start_idx]#Calculates start/end positions and formats region string for VCF slicing.\n",
    "    end_pos = chr1_positions[end_idx - 1]\n",
    "\n",
    "    region_str = f\"{chrom}:{start_pos}-{end_pos}\"\n",
    "    print(f\"Processing region: {region_str}\")\n",
    "\n",
    "    #Read VCF Chunk\n",
    "    chunk = allel.read_vcf(\n",
    "        vcf_path,\n",
    "        samples=eur_samples,\n",
    "        region=region_str,\n",
    "        fields=['variants/CHROM', 'variants/POS', 'variants/REF', 'variants/ALT', 'calldata/GT'],\n",
    "        alt_number=1\n",
    "    )#Loads genotype and variant data for the specified region and EUR samples.\n",
    "\n",
    "    #Skip Empty Chunks\n",
    "    if chunk is None or len(chunk['variants/POS']) == 0:\n",
    "        start_idx = end_idx\n",
    "        continue#Skips processing if no variants were found in the chunk.\n",
    "\n",
    "    genotypes = allel.GenotypeArray(chunk['calldata/GT'])## Convert to GenotypeArray\n",
    "    allele_counts = genotypes.count_alleles()## Count alleles per variant\n",
    "    alt_freqs = allele_counts[:, 1] / allele_counts.sum(axis=1)## ALT allele frequency\n",
    "\n",
    "    alts = chunk['variants/ALT']\n",
    "    if alts.ndim == 2:\n",
    "        alts = alts[:, 0]#If ALT alleles are stored as 2D arrays (e.g., multiple alleles), extract the first.\n",
    "\n",
    "    #Create DataFrame for Chunk\n",
    "    df_chunk = pd.DataFrame({\n",
    "        'chr': chunk['variants/CHROM'],\n",
    "        'pos': chunk['variants/POS'],\n",
    "        'ref': chunk['variants/REF'],\n",
    "        'alt': alts,\n",
    "        'alt_freq_eur': alt_freqs\n",
    "    })\n",
    "\n",
    "    # Write chunks in batches\n",
    "    if (start_idx // chunk_size) % batch_size == 0:\n",
    "        # Save all chunks in batch to CSV\n",
    "        df_chunk.to_csv(output_file, mode='a', header=first_chunk, index=False, compression='gzip')\n",
    "        first_chunk = False\n",
    "\n",
    "    start_idx = end_idx\n",
    "\n",
    "print(f\"✅ Finished saving to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbdaa2-66e4-4d54-950f-ed6dc22f0651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"allele_freq_chr1.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdd6f3-96d4-4915-840e-e57b95f639f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Define the path to your gzipped scoring file\n",
    "pgs_scoring_file = \"C:/Users/emman/Downloads/PM2.5_Pollution_Data-Public/Scripts/Genetic_Data/GEO_Accession_Genetic_Data/PGS000018.txt.gz\"\n",
    "\n",
    "#Load the file using pandas with robust settings\n",
    "pgs_df = pd.read_csv(\n",
    "    pgs_scoring_file, ## File path\n",
    "    sep='\\t', ## Tab-separated values\n",
    "    compression='gzip', ## File is gzipped\n",
    "    comment='#',         # Skip all comment lines starting with '#'\n",
    "    engine='python', # More tolerant parser than default 'c'\n",
    "    on_bad_lines='skip' # Skip malformed lines instead of raising errors\n",
    ")\n",
    "\n",
    "#Display the first few rows of the parsed DataFrame\n",
    "print(pgs_df.head())\n",
    "print(pgs_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc8ba8-d8aa-48db-93aa-77f4674945d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Genetic Data Columns:\", genetic_df.columns.tolist())\n",
    "print(\"PGS Columns:\", pgs_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5647df2c-f0a6-43de-90ed-fc9c7a4b0d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merge complete: 1744386 rows, 24 columns\n",
      "\n",
      "📄 Preview:\n",
      "         MarkerName Allele1 Allele2   Freq1  FreqSE  MinFreq  MaxFreq  Effect  \\\n",
      "0  10:100003304_A_G       a       g  0.9636  0.0037   0.9615   0.9701  0.0066   \n",
      "1  10:100004799_A_C       a       c  0.9863  0.0014   0.9857   0.9891 -0.0185   \n",
      "2   10:10000586_C_T       t       c  0.9864  0.0020   0.9856   0.9913  0.0313   \n",
      "3  10:100009542_A_G       a       g  0.0253  0.0015   0.0225   0.0261 -0.0102   \n",
      "4  10:100015153_A_G       a       g  0.0174  0.0004   0.0166   0.0176 -0.0353   \n",
      "\n",
      "   StdErr  P-value  ... HetPVal        oldID  CHR         BP         rsID  \\\n",
      "0  0.0158   0.6787  ...  0.1433   rs72828461   10  100003304   rs72828461   \n",
      "1  0.0267   0.4873  ...  0.2299   rs77264786   10  100004799   rs77264786   \n",
      "2  0.0286   0.2737  ...  0.1131  rs190955300   10   10000586  rs190955300   \n",
      "3  0.0203   0.6153  ...  0.8578   rs11598533   10  100009542   rs11598533   \n",
      "4  0.0261   0.1773  ...  0.9068  rs141332000   10  100015153  rs141332000   \n",
      "\n",
      "  chr_name  chr_position  effect_allele other_allele  effect_weight  \n",
      "0       10     100003304              A            G      -0.000281  \n",
      "1       10     100004799              A            C      -0.000713  \n",
      "2       10      10000586              T            C       0.001192  \n",
      "3       10     100009542              G            A       0.000141  \n",
      "4       10     100015153              A            G      -0.000246  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming both files are already loaded as DataFrames\n",
    "# Example:\n",
    "# genetic_df = pd.read_csv(\"CAD_META.txt\", sep=\"\\t\")\n",
    "# pgs_df = pd.read_csv(\"PGS000018.txt.gz\", sep=\"\\t\", compression=\"gzip\", comment=\"#\")\n",
    "\n",
    "def merge_datasets(genetic_df, pgs_df, left_col=\"oldID\", right_col=\"rsID\", how=\"inner\"):\n",
    "    # Check columns exist\n",
    "    if left_col not in genetic_df.columns:\n",
    "        raise KeyError(f\"❌ Column '{left_col}' not found in genetic data\")\n",
    "    if right_col not in pgs_df.columns:\n",
    "        raise KeyError(f\"❌ Column '{right_col}' not found in PGS scoring data\")\n",
    "    \n",
    "    merged = pd.merge(genetic_df, pgs_df, left_on=left_col, right_on=right_col, how=how)\n",
    "    \n",
    "    print(f\"✅ Merge complete: {merged.shape[0]} rows, {merged.shape[1]} columns\")\n",
    "    print(\"\\n📄 Preview:\")\n",
    "    print(merged.head())\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# Example usage:\n",
    "merged_df = merge_datasets(genetic_df, pd.read_csv(pgs_scoring_file, sep=\"\\t\", compression=\"gzip\", comment=\"#\"), \"oldID\", \"rsID\", \"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011abf7-78f4-4335-8cfe-3b3baf4ad622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_with_allele_freq(merged_df, allele_freq_df, left_cols=('CHR', 'BP'), right_cols=('chr', 'pos'), how='inner'):\n",
    "    # Ensure inputs are DataFrames\n",
    "    if not isinstance(merged_df, pd.DataFrame):\n",
    "        raise TypeError(\"❌ 'merged_df' must be a pandas DataFrame\")\n",
    "    if not isinstance(allele_freq_df, pd.DataFrame):\n",
    "        raise TypeError(\"❌ 'allele_freq_df' must be a pandas DataFrame\")\n",
    "    \n",
    "    # Check required columns exist\n",
    "    for col in left_cols:\n",
    "        if col not in merged_df.columns:\n",
    "            raise KeyError(f\"❌ Column '{col}' not found in merged_df\")\n",
    "    for col in right_cols:\n",
    "        if col not in allele_freq_df.columns:\n",
    "            raise KeyError(f\"❌ Column '{col}' not found in allele_freq_df\")\n",
    "    \n",
    "    # Harmonize chromosome format (remove 'chr' prefix if needed)\n",
    "    merged_df[left_cols[0]] = merged_df[left_cols[0]].astype(str).str.replace('chr', '', case=False)\n",
    "    allele_freq_df[right_cols[0]] = allele_freq_df[right_cols[0]].astype(str).str.replace('chr', '', case=False)\n",
    "    \n",
    "    # Ensure positions are integers\n",
    "    merged_df[left_cols[1]] = merged_df[left_cols[1]].astype(int)\n",
    "    allele_freq_df[right_cols[1]] = allele_freq_df[right_cols[1]].astype(int)\n",
    "    \n",
    "    merged_full = pd.merge(merged_df, allele_freq_df, left_on=left_cols, right_on=right_cols, how=how)\n",
    "    \n",
    "    print(f\"✅ Merge complete: {merged_full.shape[0]} rows, {merged_full.shape[1]} columns\")\n",
    "    print(\"\\n📄 Preview:\")\n",
    "    print(merged_full.head())\n",
    "    \n",
    "    return merged_full\n",
    "\n",
    "# Example usage:\n",
    "merged_full_df = merge_with_allele_freq(merged, allele_freq_df, ('CHR', 'BP'), ('chr', 'pos'), 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b74e3-80d6-47ba-8b25-34486fd96736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d50c0-2692-4ee8-b683-38652ee6aae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5c6dd-7228-4de2-b2e8-df06e1ef0ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5982b20-c771-4781-a356-b46bdc4bbf52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gwas_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Filter for genome-wide significant SNPs (p-value < 5e-8)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m significance_snps = \u001b[43mgwas_df\u001b[49m[gwas_df[\u001b[33m'\u001b[39m\u001b[33mP-value\u001b[39m\u001b[33m'\u001b[39m] < \u001b[32m5e-8\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Keep only needed columns: MarkerName, Effect allele, Effect size, P-value, chromosome, position\u001b[39;00m\n\u001b[32m      4\u001b[39m filtered_gwas = sig_snps[[\u001b[33m'\u001b[39m\u001b[33mMarkerName\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAllele1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEffect\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mP-value\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCHR\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mBP\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[31mNameError\u001b[39m: name 'gwas_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter for genome-wide significant SNPs (p-value < 5e-8)\n",
    "significance_snps = gwas_df[gwas_df['P-value'] < 5e-8]\n",
    "# Keep only needed columns: MarkerName, Effect allele, Effect size, P-value, chromosome, position\n",
    "filtered_gwas = sig_snps[['MarkerName', 'Allele1', 'Effect', 'P-value', 'CHR', 'BP']]\n",
    "print(f\"Number of significant SNPs: {filtered_gwas.shape[0]}\")\n",
    "filtered_gwas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbd6bf-813c-4b1a-909c-00d6d8ca5d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
