{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e602b6d7-e1a9-4dec-8ab6-3ec84d74db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0: Import necessary libraries\n",
    "import pandas as pd                     # For data manipulation\n",
    "import numpy as np                      # For numerical operations\n",
    "from datetime import datetime           # To record timestamp in metadata\n",
    "import json                             # To save metadata as a JSON file\n",
    "import os #OS module = To check if file exist\n",
    "\n",
    "# STEP 1: Load the cleaned, imputed dataset (from Rule 7)\n",
    "prophet_imputed_environmental_data = os.path.join(\"C:/Users/emman/Downloads/PM2.5_Pollution_Data-Public/Scripts/Finial_Prophet_Imputed_Cleaned_Environmental_Data.csv\")\n",
    "df = pd.read_csv(prophet_imputed_environmental_data)\n",
    "\n",
    "# STEP 2: Identify continuous PM2.5 columns for normalization\n",
    "# We are normalizing these to a 0‚Äì1 range using Min-Max scaling\n",
    "# STEP 2: Identify continuous PM2.5 columns for normalization (corrected)\n",
    "pm25_cols = [\n",
    "    'PM2.5_Anthropogenic',\n",
    "    'PM2.5_Non_Anthropogenic',\n",
    "    'PM2.5_Total'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6077bbce-9ac7-4a56-9f18-cfaf39b8973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Initialize a dictionary to store scaling info\n",
    "# This helps track min and max values for each column\n",
    "scaling_info = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fe57df1-5fc6-47e1-9afb-a5e2282f43e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Numeric Area Code', 'Area Code', 'Local Authority Name', 'Year', 'PM2.5_Anthropogenic', 'PM2.5_Non_Anthropogenic', 'PM2.5_Total', 'PM2.5_Anthropogenic_ImputationMethod', 'PM2.5_Non_Anthropogenic_ImputationMethod', 'PM2.5_Total_ImputationMethod']\n",
      "Available columns:\n",
      "['Numeric Area Code', 'Area Code', 'Local Authority Name', 'Year', 'PM2.5_Anthropogenic', 'PM2.5_Non_Anthropogenic', 'PM2.5_Total', 'PM2.5_Anthropogenic_ImputationMethod', 'PM2.5_Non_Anthropogenic_ImputationMethod', 'PM2.5_Total_ImputationMethod']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "df.columns = df.columns.str.strip()  # Remove leading/trailing spaces\n",
    "# Optional debug step:\n",
    "print(\"Available columns:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ec479dd-1f21-4bda-add2-b0270dc5704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Apply Min-Max Scaling to each PM2.5 column\n",
    "# We scale AFTER imputation, as required by Rule 9\n",
    "\n",
    "for col in pm25_cols:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "\n",
    "    # Save original min and max for metadata documentation\n",
    "    scaling_info[col] = {'min': min_val, 'max': max_val}\n",
    "\n",
    "    # Avoid division by zero in case min == max\n",
    "    if max_val != min_val:\n",
    "        df[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        df[col] = 0.0  # If constant column, assign scaled value of 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a222e66b-cb51-4aec-9093-c7e4e2666861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: Save the normalized DataFrame to a new CSV file\n",
    "# This satisfies Rule 10 for reproducibility\n",
    "\n",
    "output_filename = \"Final_Environmental_Data_Normalized_For_ML.csv\"\n",
    "df.to_csv(output_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703e46ae-109b-4888-8c71-b6e4b895216c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Save metadata as a JSON file\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal_Environmental_Data_Metadata.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Personal_File\\University_of_Bradford\\Lib\\json\\__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Personal_File\\University_of_Bradford\\Lib\\json\\encoder.py:432\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    430\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Personal_File\\University_of_Bradford\\Lib\\json\\encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Personal_File\\University_of_Bradford\\Lib\\json\\encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Personal_File\\University_of_Bradford\\Lib\\json\\encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Personal_File\\University_of_Bradford\\Lib\\json\\encoder.py:439\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\Personal_File\\University_of_Bradford\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "#STEP 6: Generate metadata (Rule 12)\n",
    "# Includes timestamp, row count, scaling info, imputation method counts\n",
    "\n",
    "# Identify tracking columns used for imputation\n",
    "imputed_cols = [\n",
    "    'PM2.5_Anthropogenic_ImputationMethod',\n",
    "    'PM2.5_Non_Anthropogenic_ImputationMethod',\n",
    "    'PM2.5_Total_ImputationMethod'\n",
    "]\n",
    "\n",
    "# Count how many rows used Prophet or Median for each PM2.5 metric\n",
    "imputation_summary = {}\n",
    "for col in imputed_cols:\n",
    "    imputation_summary[col] = dict(df[col].value_counts(dropna=False))\n",
    "\n",
    "# Count total number of rows in the final dataset\n",
    "rows_final = df.shape[0]\n",
    "\n",
    "# Compile all metadata into a dictionary\n",
    "metadata = {\n",
    "    'Timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'Final_Row_Count': rows_final,\n",
    "    'PM2.5_Columns_Scaled': pm25_cols,\n",
    "    'Scaling_Parameters': scaling_info,\n",
    "    'Imputation_Method_Counts': imputation_summary,\n",
    "    'Note': (\n",
    "        \"Data has been imputed (Prophet or Median), normalized using Min-Max scaling, \"\n",
    "        \"and exported for use in ML pipelines. Tracking columns were excluded from scaling.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Save metadata as a JSON file\n",
    "with open(\"Final_Environmental_Data_Metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08c0aa-bc7f-4196-93c6-df96bf5c0cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final print summary for the user\n",
    "\n",
    "print(\"‚úÖ Rules 8‚Äì12 successfully applied.\")\n",
    "print(f\"üìÅ Normalized dataset saved to: {output_filename}\")\n",
    "print(\"üìÑ Metadata saved to: Final_Environmental_Data_Metadata.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
